{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356b768c-0eb8-41bc-bc9c-545c6401e1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, io, json, math, tempfile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "\n",
    "# Try OpenCV\n",
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\"])\n",
    "    import cv2\n",
    "\n",
    "# Try Folium\n",
    "try:\n",
    "    import folium\n",
    "except:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"folium\"])\n",
    "    import folium\n",
    "\n",
    "gr.close_all()\n",
    "\n",
    "# ---------- Utility ----------\n",
    "def pil_from_upload(upload):\n",
    "    if upload is None:\n",
    "        return None\n",
    "    return Image.open(upload.name).convert(\"RGB\")\n",
    "\n",
    "# ---------- Simple Leaf Disease Heuristic ----------\n",
    "def leaf_disease_heuristic(pil_img):\n",
    "    img = pil_img.resize((512, 512))\n",
    "    arr = np.array(img)\n",
    "\n",
    "    hsv = cv2.cvtColor(arr, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    mask = (v < 120).astype(np.uint8) * 255\n",
    "    percent = (mask > 0).sum() / mask.size * 100\n",
    "\n",
    "    overlay = arr.copy()\n",
    "    overlay[mask > 0] = [255, 0, 0]\n",
    "    overlay = Image.fromarray(overlay).resize(pil_img.size)\n",
    "\n",
    "    if percent < 2:\n",
    "        severity = \"Healthy\"\n",
    "        suggestion = \"Leaf appears healthy.\"\n",
    "    elif percent < 5:\n",
    "        severity = \"Mild Infection\"\n",
    "        suggestion = \"Early_first stage disease detected.\"\n",
    "    else:\n",
    "        severity = \"Severe Infection\"\n",
    "        suggestion = \"Needs immediate treatment.\"\n",
    "\n",
    "    return percent, severity, suggestion, overlay\n",
    "\n",
    "# ---------- NDVI Approx ----------\n",
    "def pseudo_ndvi(pil_img):\n",
    "    img = pil_img.resize((512, 512))\n",
    "    arr = np.array(img).astype(float)\n",
    "\n",
    "    R = arr[:, :, 0]\n",
    "    G = arr[:, :, 1]\n",
    "    ndvi = (G - R) / (G + R + 1e-6)\n",
    "\n",
    "    nd = (ndvi + 1) / 2\n",
    "    nd = np.clip(nd, 0, 1)\n",
    "\n",
    "    heat = np.uint8(plt_colormap(nd) * 255)\n",
    "    heat = Image.fromarray(heat).resize(pil_img.size)\n",
    "\n",
    "    return float(np.mean(ndvi)), heat\n",
    "\n",
    "def plt_colormap(mat):\n",
    "    import matplotlib.cm as cm\n",
    "    cmap = cm.get_cmap(\"viridis\")\n",
    "    return cmap(mat)[..., :3]\n",
    "\n",
    "# ---------- Field Map ----------\n",
    "def make_field_map(lat, lon):\n",
    "    m = folium.Map(location=[lat, lon], zoom_start=17)\n",
    "    folium.Marker([lat, lon], popup=\"Farm Center\").add_to(m)\n",
    "\n",
    "    tmp = tempfile.NamedTemporaryFile(suffix=\".html\", delete=False)\n",
    "    m.save(tmp.name)\n",
    "    return open(tmp.name).read()\n",
    "\n",
    "# ---------- Forecast ----------\n",
    "def forecast(series, steps=7):\n",
    "    x = np.arange(len(series))\n",
    "    y = np.array(series)\n",
    "    p = np.polyfit(x, y, 1)\n",
    "    preds = np.polyval(p, np.arange(len(series), len(series) + steps))\n",
    "    return preds.tolist()\n",
    "\n",
    "# ---------- Main Function ----------\n",
    "def analyze(upload_img, lat, lon, csv_file):\n",
    "\n",
    "    pil = pil_from_upload(upload_img)\n",
    "    if pil is None:\n",
    "        return None, \"Please upload image\", None, None, None\n",
    "\n",
    "    # Leaf\n",
    "    percent, severity, suggestion, overlay = leaf_disease_heuristic(pil)\n",
    "\n",
    "    # NDVI\n",
    "    ndvi_mean, ndvi_img = pseudo_ndvi(pil)\n",
    "\n",
    "    # Map\n",
    "    map_html = make_field_map(lat, lon)\n",
    "\n",
    "    # CSV or synthetic\n",
    "    if csv_file:\n",
    "        df = pd.read_csv(csv_file.name)\n",
    "        series = df.select_dtypes(include=np.number).iloc[:, 0].tolist()\n",
    "    else:\n",
    "        series = [30 + 5*np.sin(i/3) for i in range(20)]\n",
    "\n",
    "    preds = forecast(series)\n",
    "\n",
    "    chart = {\n",
    "        \"history\": series,\n",
    "        \"forecast\": preds\n",
    "    }\n",
    "\n",
    "    return overlay, f\"{severity}\\nAffected: {percent}%\\n{suggestion}\", ndvi_img, map_html, json.dumps(chart, indent=2)\n",
    "\n",
    "# ---------- UI ----------\n",
    "with gr.Blocks(title=\"AI Agriculture Monitoring\") as demo:\n",
    "\n",
    "    gr.HTML(\"\"\"\n",
    "    <style>\n",
    "        body { background:#072540; color:white; }\n",
    "        .gradio-container { background:#0A1B2A; color:white; }\n",
    "    </style>\n",
    "    \"\"\")\n",
    "\n",
    "    gr.Markdown(\"## ðŸŒ¾ AI Agriculture Monitoring Platform (Working Version)\")\n",
    "\n",
    "    upload = gr.File(label=\"Upload Leaf Image\")\n",
    "    lat = gr.Number(value=28.7041, label=\"Latitude\")\n",
    "    lon = gr.Number(value=77.1025, label=\"Longitude\")\n",
    "    csv_in = gr.File(label=\"Sensor CSV\")\n",
    "\n",
    "    btn = gr.Button(\"Analyze Farm ðŸ§ª\")\n",
    "\n",
    "    out_overlay = gr.Image(label=\"Leaf Analysis\", type=\"pil\")\n",
    "    out_text = gr.Textbox(label=\"Diagnosis\", lines=4)\n",
    "    out_ndvi = gr.Image(label=\"NDVI Heatmap\", type=\"pil\")\n",
    "    out_map = gr.HTML(label=\"Farm Map\")\n",
    "    out_chart = gr.Textbox(label=\"Forecast Data\", lines=8)\n",
    "\n",
    "    btn.click(analyze, [upload, lat, lon, csv_in],\n",
    "              [out_overlay, out_text, out_ndvi, out_map, out_chart])\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81fb1cef-1e58-4ab2-b117-c600918e4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7863\n",
      "Closing server running on port: 7864\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 763, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2106, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1588, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\mayur\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 1048, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Temp\\ipykernel_13020\\1629692572.py\", line 327, in run_pipeline\n",
      "    drone_html = drone_map(lat,lon,drone_files,drone_bounds)\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Temp\\ipykernel_13020\\1629692572.py\", line 236, in drone_map\n",
      "    with open(tmp,\"wb\") as o: o.write(f.read())\n",
      "                                      ^^^^^^\n",
      "AttributeError: 'NamedString' object has no attribute 'read'\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# MEGA AI AGRICULTURE MONITORING PLATFORM\n",
    "# v3 â€” FULLY FIXED FOR GRADIO 3.x\n",
    "##############################################\n",
    "\n",
    "import os, io, sys, json, tempfile, shutil, math, subprocess\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "\n",
    "# --------- Auto-install missing ---------\n",
    "def safe_install(p):\n",
    "    try:\n",
    "        __import__(p)\n",
    "    except:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p])\n",
    "\n",
    "# OpenCV\n",
    "try: import cv2\n",
    "except: safe_install(\"opencv-python\"); import cv2\n",
    "\n",
    "# Torch + Vision\n",
    "try: import torch, torchvision\n",
    "except:\n",
    "    safe_install(\"torch\"); safe_install(\"torchvision\")\n",
    "    import torch, torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Folium for map\n",
    "try: import folium\n",
    "except: safe_install(\"folium\"); import folium\n",
    "\n",
    "# Matplotlib\n",
    "try: import matplotlib.pyplot as plt\n",
    "except: safe_install(\"matplotlib\"); import matplotlib.pyplot as plt\n",
    "\n",
    "# YOLO optional\n",
    "YOLO_AVAILABLE = False\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    YOLO_AVAILABLE = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_PATH = \"leaf_model.pth\"\n",
    "YOLO_MODEL = \"yolov8s-seg.pt\"\n",
    "\n",
    "###################################################\n",
    "# Utility\n",
    "###################################################\n",
    "def pil_from_upload(upload):\n",
    "    if upload is None:\n",
    "        return None\n",
    "    return Image.open(upload.name).convert(\"RGB\")\n",
    "\n",
    "def save_temp(pil, fname=\"temp.png\"):\n",
    "    p = Path(fname)\n",
    "    pil.save(p)\n",
    "    return str(p.resolve())\n",
    "\n",
    "###################################################\n",
    "# MODEL SECTION â€” RESNET18 CLASSIFIER\n",
    "###################################################\n",
    "\n",
    "def create_resnet(num_classes):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "infer_tf = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def predict_leaf(pil, classes, model):\n",
    "    model.eval()\n",
    "    x = infer_tf(pil).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "        probs = torch.softmax(out, dim=1)[0].cpu().numpy()\n",
    "    preds = sorted(zip(classes, probs.tolist()), key=lambda x: x[1], reverse=True)\n",
    "    return preds[0][0], float(preds[0][1]), preds\n",
    "\n",
    "def simple_gradcam(model, pil):\n",
    "    # register hooks\n",
    "    acts, grads = {}, {}\n",
    "\n",
    "    def fwd_hook(m,i,o): acts[\"v\"] = o\n",
    "    def bwd_hook(m,gi,go): grads[\"v\"] = go[0]\n",
    "\n",
    "    lh = model.layer4\n",
    "    h1 = lh.register_forward_hook(fwd_hook)\n",
    "    h2 = lh.register_full_backward_hook(bwd_hook)\n",
    "\n",
    "    model.eval()\n",
    "    x = infer_tf(pil).unsqueeze(0).to(DEVICE)\n",
    "    out = model(x)\n",
    "    cls = out.argmax().item()\n",
    "    loss = out[0, cls]\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    A = acts[\"v\"][0]  # C,H,W\n",
    "    G = grads[\"v\"][0] # C,H,W\n",
    "    w = G.mean(dim=(1,2))\n",
    "    cam = (w[:,None,None] * A).sum(0).cpu().numpy()\n",
    "    cam = np.maximum(cam,0)\n",
    "    cam = cam / (cam.max()+1e-9)\n",
    "    cam = cv2.resize(cam, pil.size[::-1])\n",
    "\n",
    "    heat = plt.get_cmap(\"jet\")(cam)[:,:,:3]\n",
    "    heat = (heat*255).astype(np.uint8)\n",
    "    overlay = cv2.addWeighted(np.array(pil), 0.6, heat, 0.4,0)\n",
    "    h1.remove(); h2.remove()\n",
    "    return Image.fromarray(overlay)\n",
    "\n",
    "###################################################\n",
    "# TRAIN FROM DATASET (OPTIONAL)\n",
    "###################################################\n",
    "\n",
    "def train_model(data_dir, epochs=3, lr=1e-4, batch=16):\n",
    "    from torchvision.datasets import ImageFolder\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    ds = ImageFolder(data_dir, transform=tfm)\n",
    "    classes = ds.classes\n",
    "    loader = torch.utils.data.DataLoader(ds, batch_size=batch, shuffle=True)\n",
    "\n",
    "    model = create_resnet(len(classes)).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        total,loss_sum=0,0\n",
    "        model.train()\n",
    "        for img,labels in loader:\n",
    "            img,labels=img.to(DEVICE),labels.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            out = model(img)\n",
    "            loss = loss_fn(out,labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            loss_sum += loss.item()*img.size(0)\n",
    "            total += img.size(0)\n",
    "        print(f\"Epoch {ep+1}/{epochs}, Loss={loss_sum/total:.4f}\")\n",
    "\n",
    "    torch.save({\"model_state\":model.state_dict(),\"classes\":classes}, MODEL_PATH)\n",
    "    return model, classes\n",
    "\n",
    "###################################################\n",
    "# NDVI (pseudo)\n",
    "###################################################\n",
    "\n",
    "def pseudo_ndvi(pil):\n",
    "    arr = np.array(pil.resize((512,512))).astype(float)\n",
    "    R,G = arr[:,:,0],arr[:,:,1]\n",
    "    ndvi = (G-R)/(G+R+1e-6)\n",
    "    nd = (ndvi+1)/2\n",
    "    heat = (plt.get_cmap(\"viridis\")(nd)[:,:,:3]*255).astype(np.uint8)\n",
    "    heat = Image.fromarray(heat).resize(pil.size)\n",
    "    return float(np.mean(ndvi)), heat\n",
    "\n",
    "###################################################\n",
    "# YOLO segmentation (optional)\n",
    "###################################################\n",
    "\n",
    "def yolo_seg(pil, model_path):\n",
    "    if not YOLO_AVAILABLE or not os.path.exists(model_path):\n",
    "        return None,\"YOLO not installed or model missing\"\n",
    "    y = YOLO(model_path)\n",
    "    temp = save_temp(pil,\"_seg_in.png\")\n",
    "    res = y.predict(temp, conf=0.25)\n",
    "    if len(res)==0: return None,\"No segmentation\"\n",
    "    arr = res[0].plot()\n",
    "    return Image.fromarray(arr), \"OK\"\n",
    "\n",
    "###################################################\n",
    "# fallback segmentation\n",
    "###################################################\n",
    "\n",
    "def fallback_seg(pil):\n",
    "    arr = np.array(pil)\n",
    "    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    _,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    th = 255-th\n",
    "    cnts,_=cv2.findContours(th,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    over = arr.copy()\n",
    "    for c in cnts:\n",
    "        area=cv2.contourArea(c)\n",
    "        if area<80: continue\n",
    "        x,y,w,h=cv2.boundingRect(c)\n",
    "        cv2.rectangle(over,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    return Image.fromarray(over)\n",
    "\n",
    "###################################################\n",
    "# Weather\n",
    "###################################################\n",
    "import requests\n",
    "def weather_api(key, lat, lon):\n",
    "    if not key: return None,\"No API key\"\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={key}&units=metric\"\n",
    "    try:\n",
    "        r=requests.get(url,timeout=8)\n",
    "        r.raise_for_status()\n",
    "        return r.json(),\"OK\"\n",
    "    except Exception as e:\n",
    "        return None,str(e)\n",
    "\n",
    "###################################################\n",
    "# Drone map overlay\n",
    "###################################################\n",
    "def drone_map(lat,lon,files,bounds_json):\n",
    "    if not files:\n",
    "        return \"<i>No drone images uploaded</i>\"\n",
    "\n",
    "    try: bounds = json.loads(bounds_json) if bounds_json else None\n",
    "    except: bounds=None\n",
    "\n",
    "    m = folium.Map(location=[lat,lon], zoom_start=17)\n",
    "    for i,f in enumerate(files):\n",
    "        ext = Path(f.name).suffix\n",
    "        tmp = f\"drone_{i}{ext}\"\n",
    "        with open(tmp,\"wb\") as o: o.write(f.read())\n",
    "        if bounds and i<len(bounds):\n",
    "            with open(tmp,\"rb\") as o:\n",
    "                b64 = base64.b64encode(o.read()).decode()\n",
    "            data_url = f\"data:image/png;base64,{b64}\"\n",
    "            folium.raster_layers.ImageOverlay(image=data_url,bounds=bounds[i],opacity=0.7).add_to(m)\n",
    "        else:\n",
    "            html = f'<img src=\"data:image/png;base64,{base64.b64encode(open(tmp,\"rb\").read()).decode()}\" width=\"300\"/>'\n",
    "            folium.Marker([lat,lon], popup=folium.Popup(html,max_width=400)).add_to(m)\n",
    "\n",
    "    tmpf = tempfile.NamedTemporaryFile(suffix=\".html\", delete=False)\n",
    "    m.save(tmpf.name)\n",
    "    return open(tmpf.name).read()\n",
    "\n",
    "###################################################\n",
    "# Time-series forecast\n",
    "###################################################\n",
    "\n",
    "def forecast(series, steps=7):\n",
    "    x=np.arange(len(series))\n",
    "    y=np.array(series)\n",
    "    p=np.polyfit(x,y,1)\n",
    "    X=np.arange(len(series),len(series)+steps)\n",
    "    return np.polyval(p,X).tolist()\n",
    "\n",
    "###################################################\n",
    "# Risk score\n",
    "###################################################\n",
    "def risk_score(ml_conf, ndvi_mean, weather):\n",
    "    score = 0\n",
    "    score += (1-ml_conf)*30\n",
    "    score += (0.5-ndvi_mean)*30\n",
    "    if weather:\n",
    "        hum = weather.get(\"main\",{}).get(\"humidity\",50)\n",
    "        temp= weather.get(\"main\",{}).get(\"temp\",25)\n",
    "        score += max(0,(hum-60))*0.3\n",
    "        if 15<temp<30: score+=5\n",
    "    return round(max(0,min(100,score)),2)\n",
    "\n",
    "###################################################\n",
    "# GLOBAL MODEL STATE\n",
    "###################################################\n",
    "STATE={\"model\":None,\"classes\":None}\n",
    "\n",
    "###################################################\n",
    "# Load/train model callback\n",
    "###################################################\n",
    "def load_or_train(dataset_dir):\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        d=torch.load(MODEL_PATH,map_location=DEVICE)\n",
    "        classes=d[\"classes\"]\n",
    "        model=create_resnet(len(classes)).to(DEVICE)\n",
    "        model.load_state_dict(d[\"model_state\"])\n",
    "        STATE[\"model\"],STATE[\"classes\"]=model,classes\n",
    "        return \"Loaded existing model.\"\n",
    "    if dataset_dir:\n",
    "        model,classes=train_model(dataset_dir)\n",
    "        STATE[\"model\"],STATE[\"classes\"]=model,classes\n",
    "        return \"Training completed.\"\n",
    "    return \"No model found. Provide dataset_dir to train.\"\n",
    "\n",
    "###################################################\n",
    "# FULL pipeline callback\n",
    "###################################################\n",
    "def run_pipeline(leaf_img, use_yolo, yolo_path, key, lat, lon, drone_files, drone_bounds, sensor_csv):\n",
    "\n",
    "    pil = pil_from_upload(leaf_img)\n",
    "    if pil is None: return \"Upload leaf first\",None,None,None,None,None,None,None,None\n",
    "\n",
    "    # ML prediction\n",
    "    if STATE[\"model\"]:\n",
    "        cls, conf, preds = predict_leaf(pil, STATE[\"classes\"], STATE[\"model\"])\n",
    "    else:\n",
    "        cls, conf, preds = \"No model\", 0.0, []\n",
    "\n",
    "    # Grad-CAM\n",
    "    gc = simple_gradcam(STATE[\"model\"], pil) if STATE[\"model\"] else None\n",
    "\n",
    "    # NDVI\n",
    "    ndval, ndimg = pseudo_ndvi(pil)\n",
    "\n",
    "    # Segmentation\n",
    "    if use_yolo and YOLO_AVAILABLE and os.path.exists(yolo_path):\n",
    "        seg,seg_msg=yolo_seg(pil,yolo_path)\n",
    "    else:\n",
    "        seg=fallback_seg(pil); seg_msg=\"Fallback segmentation.\"\n",
    "\n",
    "    # Weather\n",
    "    wjson,wmsg = weather_api(key,lat,lon) if key else (None,\"No key\")\n",
    "\n",
    "    # Drone Map\n",
    "    drone_html = drone_map(lat,lon,drone_files,drone_bounds)\n",
    "\n",
    "    # Sensor CSV\n",
    "    if sensor_csv:\n",
    "        try:\n",
    "            df = pd.read_csv(sensor_csv.name)\n",
    "            series = df.select_dtypes(include=np.number).iloc[:,0].tolist()\n",
    "        except:\n",
    "            series=[30+5*np.sin(i/3) for i in range(20)]\n",
    "    else:\n",
    "        series=[30+5*np.sin(i/3) for i in range(20)]\n",
    "\n",
    "    preds_ts = forecast(series)\n",
    "\n",
    "    # Risk\n",
    "    risk = risk_score(conf,ndval,wjson)\n",
    "\n",
    "    out = {\n",
    "        \"cls\":cls,\n",
    "        \"conf\":conf,\n",
    "        \"gc\":gc,\n",
    "        \"nd\":ndimg,\n",
    "        \"seg\":seg,\n",
    "        \"seg_msg\":seg_msg,\n",
    "        \"weather\":wjson if wjson else {\"note\":wmsg},\n",
    "        \"drone\":drone_html,\n",
    "        \"ts\":json.dumps({\"history\":series,\"forecast\":preds_ts}),\n",
    "        \"risk\":risk\n",
    "    }\n",
    "    return (f\"{cls} ({conf:.2f})\", gc, ndimg, seg, seg_msg, str(risk),\n",
    "            out[\"weather\"], out[\"drone\"], out[\"ts\"])\n",
    "\n",
    "###################################################\n",
    "# GRADIO UI\n",
    "###################################################\n",
    "gr.close_all()\n",
    "\n",
    "with gr.Blocks(title=\"Mega AI Agriculture Platform\") as demo:\n",
    "    gr.Markdown(\"## ðŸŒ± Mega AI Agriculture Monitoring (All Features Included)\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            leaf = gr.File(label=\"Upload Leaf Image\")\n",
    "            load_btn = gr.Button(\"Load/Train Model\")\n",
    "            dataset_dir = gr.Textbox(label=\"Dataset Folder (optional)\")\n",
    "            model_status = gr.Textbox(label=\"Model Status\")\n",
    "\n",
    "            use_yolo = gr.Checkbox(label=\"Use YOLOv8 Segmentation\", value=False)\n",
    "            yolo_path = gr.Textbox(label=\"YOLO Seg Model Path\", value=YOLO_MODEL)\n",
    "\n",
    "            weather_key = gr.Textbox(label=\"Weather API Key (optional)\")\n",
    "            lat = gr.Number(label=\"Latitude\", value=28.7041)\n",
    "            lon = gr.Number(label=\"Longitude\", value=77.1025)\n",
    "\n",
    "            drone_files = gr.File(label=\"Drone Images\", file_count=\"multiple\")\n",
    "            drone_bounds = gr.Textbox(label=\"Drone Bounds JSON\")\n",
    "\n",
    "            sensor_csv = gr.File(label=\"Sensor CSV (optional)\")\n",
    "            run_btn = gr.Button(\"Run Full Pipeline\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            ml_out   = gr.Textbox(label=\"Leaf Classification\")\n",
    "            gc_out   = gr.Image(type=\"pil\", label=\"Grad-CAM\")\n",
    "            nd_out   = gr.Image(type=\"pil\", label=\"NDVI Image\")\n",
    "            seg_out  = gr.Image(type=\"pil\", label=\"Segmentation\")\n",
    "            seg_msg  = gr.Textbox(label=\"Seg Message\")\n",
    "            risk_out = gr.Textbox(label=\"Risk Score (0-100)\")\n",
    "            weather_out = gr.JSON(label=\"Weather\")\n",
    "            drone_out   = gr.HTML(label=\"Drone Map\")\n",
    "            ts_out      = gr.Textbox(label=\"Time Series\", lines=6)\n",
    "\n",
    "    load_btn.click(load_or_train, [dataset_dir], [model_status])\n",
    "    run_btn.click(run_pipeline,\n",
    "                  [leaf,use_yolo,yolo_path,weather_key,lat,lon,drone_files,drone_bounds,sensor_csv],\n",
    "                  [ml_out, gc_out, nd_out, seg_out, seg_msg, risk_out, weather_out, drone_out, ts_out])\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac853cb-3899-4975-9dba-702c8e06d647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
