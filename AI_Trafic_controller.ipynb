{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08c3877-1316-4ddf-a7d5-f2e8a0970caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI Traffic Violation Detector (Helmet / Triple Riding / Approx Speed)\n",
    "# Jupyter + Gradio prototype\n",
    "#\n",
    "# How it works:\n",
    "# - Uses Ultralytics YOLO (if available) for detection (person, motorbike, helmet models)\n",
    "# - For helmet detection: either a dedicated helmet model or heuristic on head-crop with a classifier\n",
    "# - Triple riding: counts persons overlapping same motorbike bbox\n",
    "# - Speed estimation: user provides meters_per_pixel and fps -> speed (m/s -> km/h)\n",
    "#\n",
    "# Notes: For best results install ultralytics and provide appropriate models:\n",
    "#   pip install ultralytics\n",
    "#   -> use 'yolov8n.pt' for general detection, and a helmet model (helmet.pt) if available.\n",
    "#\n",
    "# Paste this cell in Jupyter and run. The app will open via Gradio.\n",
    "\n",
    "import os, io, sys, tempfile, json, time\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gradio as gr\n",
    "import subprocess\n",
    "\n",
    "# ----------------- Optional installs (only if needed) -----------------\n",
    "def safe_import_ultralytics():\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        return YOLO\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "YOLO = safe_import_ultralytics()\n",
    "YOLO_AVAILABLE = YOLO is not None\n",
    "\n",
    "# ----------------- CONFIG / DEFAULT MODELS -----------------\n",
    "# If you have models, put them in working directory and update paths here:\n",
    "DEFAULT_YOLO_MODEL = \"yolov8n.pt\"   # general model (person, motorbike)\n",
    "DEFAULT_HELMET_MODEL = None         # e.g., \"helmet.pt\" if you trained or downloaded one\n",
    "\n",
    "# COCO class names (standard yolov8) - used if model is coco-trained\n",
    "COCO_NAMES = [\n",
    " 'person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light',\n",
    " # truncated... but we only need 'person' and 'motorcycle'\n",
    "]\n",
    "\n",
    "# ----------------- Utility helpers -----------------\n",
    "def load_yolo_model(path):\n",
    "    if not YOLO_AVAILABLE:\n",
    "        raise RuntimeError(\"Ultralytics YOLO not installed. Install via `pip install ultralytics` for best results.\")\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"YOLO model not found at: {path}\")\n",
    "    return YOLO(path)\n",
    "\n",
    "def draw_boxes(img, detections, labels=None, colors=None, line_thickness=2):\n",
    "    # img: numpy BGR\n",
    "    # detections: list of dicts: {'xyxy':(x1,y1,x2,y2), 'label':str, 'conf':float}\n",
    "    img_draw = img.copy()\n",
    "    for det in detections:\n",
    "        x1,y1,x2,y2 = map(int, det['xyxy'])\n",
    "        lab = det.get('label', '')\n",
    "        conf = det.get('conf', None)\n",
    "        color = (0,255,0) if (colors is None) else colors.get(lab, (0,255,0))\n",
    "        cv2.rectangle(img_draw, (x1,y1), (x2,y2), color, line_thickness)\n",
    "        txt = f\"{lab}\"\n",
    "        if conf is not None:\n",
    "            txt += f\" {conf:.2f}\"\n",
    "        # put text background\n",
    "        ((tw,th),_) = cv2.getTextSize(txt, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(img_draw, (x1, y1-th-6), (x1+tw+6, y1), color, -1)\n",
    "        cv2.putText(img_draw, txt, (x1+3, y1-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
    "    return img_draw\n",
    "\n",
    "def bbox_iou(boxA, boxB):\n",
    "    # boxes in x1,y1,x2,y2\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "    if interArea == 0: return 0.0\n",
    "    boxAArea = (boxA[2]-boxA[0])*(boxA[3]-boxA[1])\n",
    "    boxBArea = (boxB[2]-boxB[0])*(boxB[3]-boxB[1])\n",
    "    iou = interArea / (boxAArea + boxBArea - interArea + 1e-9)\n",
    "    return iou\n",
    "\n",
    "# ----------------- Detection pipeline -----------------\n",
    "class Detector:\n",
    "    def __init__(self, yolo_model_path=None, helmet_model_path=None, conf_thres=0.25):\n",
    "        self.yolo_model_path = yolo_model_path or DEFAULT_YOLO_MODEL\n",
    "        self.helmet_model_path = helmet_model_path or DEFAULT_HELMET_MODEL\n",
    "        self.conf_thres = conf_thres\n",
    "        self.yolo_model = None\n",
    "        self.helmet_model = None\n",
    "        if YOLO_AVAILABLE and os.path.exists(self.yolo_model_path):\n",
    "            try:\n",
    "                self.yolo_model = load_yolo_model(self.yolo_model_path)\n",
    "            except Exception as e:\n",
    "                print(\"Could not load YOLO model:\", e)\n",
    "        else:\n",
    "            if not YOLO_AVAILABLE:\n",
    "                print(\"Ultralytics not installed; detection will not use YOLO.\")\n",
    "            else:\n",
    "                print(f\"YOLO model not found at {self.yolo_model_path}; detection will try fallback.\")\n",
    "        # helmet model optional (if you have a custom model that predicts helmet vs no-helmet)\n",
    "        if YOLO_AVAILABLE and self.helmet_model_path and os.path.exists(self.helmet_model_path):\n",
    "            try:\n",
    "                self.helmet_model = load_yolo_model(self.helmet_model_path)\n",
    "            except Exception as e:\n",
    "                print(\"Could not load helmet model:\", e)\n",
    "\n",
    "    def detect_frame(self, frame_bgr):\n",
    "        \"\"\"\n",
    "        returns detections: list of dicts {'xyxy':(x1,y1,x2,y2), 'label':str, 'conf':float}\n",
    "        labels of interest: 'person', 'motorcycle', 'helmet' (if available)\n",
    "        \"\"\"\n",
    "        dets = []\n",
    "        h,w = frame_bgr.shape[:2]\n",
    "        if self.yolo_model:\n",
    "            # run YOLO predict\n",
    "            results = self.yolo_model.predict(frame_bgr, imgsz=640, conf=self.conf_thres, verbose=False)\n",
    "            if len(results) > 0:\n",
    "                r = results[0]\n",
    "                boxes = r.boxes  # ultralytics Boxes object\n",
    "                # r.boxes.cls (tensor), r.boxes.conf, r.boxes.xyxy\n",
    "                for i in range(len(boxes)):\n",
    "                    cls_id = int(boxes.cls[i].item())\n",
    "                    conf = float(boxes.conf[i].item())\n",
    "                    xyxy = boxes.xyxy[i].cpu().numpy().tolist()\n",
    "                    # label mapping: if model is coco, class names 'person'=0, 'motorcycle'=3 usually; but safer to use .names\n",
    "                    label = str(r.names[cls_id]) if hasattr(r, \"names\") else str(cls_id)\n",
    "                    dets.append({\"xyxy\":xyxy, \"label\":label, \"conf\":conf})\n",
    "        else:\n",
    "            # fallback: use OpenCV DNN MobileNet-SSD to detect persons (coarse)\n",
    "            # load model files if present in working directory\n",
    "            prototxt = \"MobileNetSSD_deploy.prototxt\"\n",
    "            caffemodel = \"MobileNetSSD_deploy.caffemodel\"\n",
    "            if os.path.exists(prototxt) and os.path.exists(caffemodel):\n",
    "                net = cv2.dnn.readNetFromCaffe(prototxt, caffemodel)\n",
    "                blob = cv2.dnn.blobFromImage(frame_bgr, 0.007843, (300,300), 127.5)\n",
    "                net.setInput(blob)\n",
    "                detections = net.forward()\n",
    "                for i in range(detections.shape[2]):\n",
    "                    conf = float(detections[0,0,i,2])\n",
    "                    if conf < self.conf_thres: continue\n",
    "                    cls_id = int(detections[0,0,i,1])\n",
    "                    # MobileNetSSD class 15 is person (depends on prototxt)\n",
    "                    # We map person class id to label 'person' for safety\n",
    "                    if cls_id == 15:\n",
    "                        box = detections[0,0,i,3:7] * np.array([frame_bgr.shape[1], frame_bgr.shape[0],\n",
    "                                                                 frame_bgr.shape[1], frame_bgr.shape[0]])\n",
    "                        x1,y1,x2,y2 = box.astype(\"int\").tolist()\n",
    "                        dets.append({\"xyxy\":(x1,y1,x2,y2), \"label\":\"person\", \"conf\":conf})\n",
    "            else:\n",
    "                # no detector available\n",
    "                pass\n",
    "        return dets\n",
    "\n",
    "# ----------------- Violation logic -----------------\n",
    "def analyze_detections(dets, iou_thresh=0.3):\n",
    "    \"\"\"\n",
    "    From detections create associations:\n",
    "      - motorbike boxes -> riders (persons overlapping)\n",
    "      - helmet check: if a helmet detection overlaps with a person head region -> helmet present\n",
    "    Returns violations list and annotated detection info\n",
    "    \"\"\"\n",
    "    bikes = [d for d in dets if d['label'] in ('motorcycle','motorbike','motor-bike','motorbike'.lower()) or d['label']=='motorcycle']\n",
    "    persons = [d for d in dets if d['label']=='person']\n",
    "    helmets = [d for d in dets if d['label'] in ('helmet','hardhat')]  # if helmet model used\n",
    "    # Normalize labels: YOLO naming may be 'motorcycle' or 'motorbike' depending on dataset; allow both by checking substring\n",
    "    bikes = [d for d in dets if ('motor' in d['label'].lower())]\n",
    "    persons = [d for d in dets if d['label'].lower()=='person']\n",
    "\n",
    "    violations = []\n",
    "    associations = []  # list of dicts per bike {'bike':bike_det, 'riders':[person_dets], 'helmet_flags':[True/False per rider]}\n",
    "    for bike in bikes:\n",
    "        bx = bike['xyxy']\n",
    "        riders = []\n",
    "        helmet_flags = []\n",
    "        for p in persons:\n",
    "            px = p['xyxy']\n",
    "            iou = bbox_iou(bx, px)\n",
    "            # also allow overlap area percentage\n",
    "            if iou > 0.01:  # low threshold: some overlap\n",
    "                riders.append(p)\n",
    "                # helmet check by overlap with any helmet detection\n",
    "                has_helmet = False\n",
    "                for h in helmets:\n",
    "                    if bbox_iou(h['xyxy'], px) > 0.2:\n",
    "                        has_helmet = True\n",
    "                        break\n",
    "                helmet_flags.append(has_helmet)\n",
    "        associations.append({\"bike\":bike, \"riders\":riders, \"helmets\":helmet_flags})\n",
    "        # triple riding violation\n",
    "        if len(riders) >= 3:\n",
    "            violations.append({\"type\":\"triple_riding\", \"bike\":bike, \"count\":len(riders)})\n",
    "        # helmet violations: for each rider, if helmet flag False -> violation\n",
    "        for idx, has in enumerate(helmet_flags):\n",
    "            if not has:\n",
    "                viol = {\"type\":\"no_helmet\", \"bike\":bike, \"rider\":riders[idx]}\n",
    "                violations.append(viol)\n",
    "    # persons not associated to any bike: check if riding without bike? ignore\n",
    "    return violations, associations\n",
    "\n",
    "# ----------------- Speed estimation -----------------\n",
    "def estimate_speeds(track_history, meters_per_pixel, fps):\n",
    "    \"\"\"\n",
    "    track_history: dict per track_id -> list of centers [(x,y,frame_idx), ...]\n",
    "    meters_per_pixel: real world meters per pixel (user must provide)\n",
    "    fps: frames per second of video\n",
    "    returns speeds dict track_id->speed_kmph (based on last two positions)\n",
    "    \"\"\"\n",
    "    speeds = {}\n",
    "    for tid, pts in track_history.items():\n",
    "        if len(pts) < 2:\n",
    "            speeds[tid] = 0.0\n",
    "            continue\n",
    "        # use last two positions\n",
    "        x1,y1,f1 = pts[-2]\n",
    "        x2,y2,f2 = pts[-1]\n",
    "        dx = (x2 - x1)\n",
    "        dy = (y2 - y1)\n",
    "        pixel_dist = np.sqrt(dx*dx + dy*dy)\n",
    "        meters = pixel_dist * meters_per_pixel\n",
    "        # time delta in seconds between frames\n",
    "        dt = (f2 - f1) / fps if fps>0 else 1.0/fps if fps else 1.0\n",
    "        if dt <= 0:\n",
    "            speed_m_s = 0.0\n",
    "        else:\n",
    "            speed_m_s = meters / dt\n",
    "        speed_kmph = speed_m_s * 3.6\n",
    "        speeds[tid] = speed_kmph\n",
    "    return speeds\n",
    "\n",
    "# ----------------- Simple multi-object tracker (centroid + greedy) -----------------\n",
    "def simple_tracker_assign(prev_centroids, curr_centroids, max_dist=50):\n",
    "    \"\"\"\n",
    "    prev_centroids: dict id -> (x,y)\n",
    "    curr_centroids: list of (x,y)\n",
    "    returns mapping new_id_for_curr_index, updated prev dict\n",
    "    \"\"\"\n",
    "    assigned = {}\n",
    "    used_prev = set()\n",
    "    new_prev = {}\n",
    "    for i, c in enumerate(curr_centroids):\n",
    "        best_id = None\n",
    "        best_d = None\n",
    "        for pid, pc in prev_centroids.items():\n",
    "            d = np.hypot(c[0]-pc[0], c[1]-pc[1])\n",
    "            if d <= max_dist and (best_d is None or d < best_d) and pid not in used_prev:\n",
    "                best_d = d; best_id = pid\n",
    "        if best_id is not None:\n",
    "            assigned[i] = best_id\n",
    "            used_prev.add(best_id)\n",
    "            new_prev[best_id] = c\n",
    "        else:\n",
    "            # new id\n",
    "            new_id = max(prev_centroids.keys() or [0]) + len(new_prev) + 1\n",
    "            assigned[i] = new_id\n",
    "            new_prev[assigned[i]] = c\n",
    "    return assigned, new_prev\n",
    "\n",
    "# ----------------- Main processing for video -----------------\n",
    "def process_video(video_path, detector:Detector, meters_per_pixel=None, fps=None, speed_threshold_kmph=None, save_out=\"annotated_out.mp4\"):\n",
    "    \"\"\"\n",
    "    Reads video, applies detection per frame, builds simple tracking for motorbikes, detects violations, writes annotated video.\n",
    "    Returns path to annotated video and report (list of violation records).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open video: \"+video_path)\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "    out_video = None\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out_video = cv2.VideoWriter(save_out, fourcc, video_fps, (frame_w, frame_h))\n",
    "\n",
    "    # trackers history: track_id -> list of (cx,cy,frame_idx)\n",
    "    bike_tracks = {}  # id -> history\n",
    "    prev_centroids = {}\n",
    "    next_track_id = 1\n",
    "\n",
    "    reports = []  # list of violation dicts with frame index, type, details\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "        dets = detector.detect_frame(frame)\n",
    "        # identify bikes and persons\n",
    "        bikes = [d for d in dets if 'motor' in d['label'].lower()]\n",
    "        persons = [d for d in dets if d['label'].lower()=='person']\n",
    "        # compute centroids of bikes\n",
    "        curr_centroids = []\n",
    "        bike_map = []  # maps centroid index -> bike det\n",
    "        for b in bikes:\n",
    "            x1,y1,x2,y2 = map(int, b['xyxy'])\n",
    "            cx = int((x1+x2)/2); cy = int((y1+y2)/2)\n",
    "            curr_centroids.append((cx,cy))\n",
    "            bike_map.append(b)\n",
    "        # assign trackers\n",
    "        assigned, new_prev = simple_tracker_assign(prev_centroids, curr_centroids, max_dist=60)\n",
    "        # rebuild bike_tracks based on assigned\n",
    "        new_bike_tracks = {}\n",
    "        for idx, tid in assigned.items():\n",
    "            cx,cy = curr_centroids[idx]\n",
    "            if tid in bike_tracks:\n",
    "                hist = bike_tracks[tid]\n",
    "            else:\n",
    "                hist = []\n",
    "            hist.append((cx,cy,frame_idx))\n",
    "            new_bike_tracks[tid] = hist\n",
    "        bike_tracks = new_bike_tracks\n",
    "        prev_centroids = new_prev\n",
    "\n",
    "        # Build combined detections for associations and violation checking\n",
    "        # Convert persons to (xyxy) arrays and check overlap with bikes\n",
    "        combined_dets = dets\n",
    "        violations, associations = analyze_detections(combined_dets)\n",
    "        # Speed estimates\n",
    "        speed_info = {}\n",
    "        if meters_per_pixel and fps:\n",
    "            speed_info = estimate_speeds(bike_tracks, meters_per_pixel, fps)\n",
    "            # check speed violations\n",
    "            if speed_threshold_kmph:\n",
    "                for tid,speed in speed_info.items():\n",
    "                    if speed > speed_threshold_kmph:\n",
    "                        # find approximate bike bbox (closest centroid)\n",
    "                        reports.append({\"frame\":frame_idx, \"type\":\"speeding\", \"track_id\":tid, \"speed_kmph\":round(speed,2)})\n",
    "                        # mark on frame\n",
    "        # Add annotation info to frame\n",
    "        ann = []\n",
    "        for d in combined_dets:\n",
    "            ann.append(d)\n",
    "        # draw boxes\n",
    "        color_map = {\"person\":(0,200,255), \"motorcycle\":(0,255,0), \"motorbike\":(0,255,0), \"helmet\":(0,128,255)}\n",
    "        frame_annot = draw_boxes(frame, ann, colors=color_map, line_thickness=2)\n",
    "        # overlay violations as text\n",
    "        y0 = 30\n",
    "        for v in violations:\n",
    "            if v['type']=='triple_riding':\n",
    "                txt = f\"Triple Riding detected (count={v['count']})\"\n",
    "                cv2.putText(frame_annot, txt, (10,y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2); y0 += 25\n",
    "                reports.append({\"frame\":frame_idx, \"type\":\"triple_riding\", \"count\":v['count']})\n",
    "            elif v['type']=='no_helmet':\n",
    "                txt = f\"No Helmet detected!\"\n",
    "                cv2.putText(frame_annot, txt, (10,y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2); y0 += 25\n",
    "                reports.append({\"frame\":frame_idx, \"type\":\"no_helmet\"})\n",
    "        # show speed info\n",
    "        if speed_info:\n",
    "            for tid, sp in speed_info.items():\n",
    "                txt = f\"Track {tid}: {sp:.1f} km/h\"\n",
    "                cv2.putText(frame_annot, txt, (frame_w-220, 20 + 18*tid), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
    "        out_video.write(frame_annot)\n",
    "\n",
    "    cap.release()\n",
    "    out_video.release()\n",
    "    return save_out, reports, {\"fps\":video_fps, \"frames\": total_frames}\n",
    "\n",
    "# ----------------- Gradio App -----------------\n",
    "def run_on_input(image_file, video_file, yolo_model_file, helmet_model_file, meters_per_pixel, fps_input, speed_limit_kmph):\n",
    "    \"\"\"\n",
    "    If video_file provided, process video; else if image_file provided, run detection on single image.\n",
    "    \"\"\"\n",
    "    detector = Detector(yolo_model_path=yolo_model_file.name if hasattr(yolo_model_file, \"name\") and yolo_model_file.name else (yolo_model_file if isinstance(yolo_model_file,str) else DEFAULT_YOLO_MODEL),\n",
    "                        helmet_model_path=helmet_model_file.name if hasattr(helmet_model_file,\"name\") and helmet_model_file.name else None)\n",
    "    # parse meters_per_pixel and fps\n",
    "    try:\n",
    "        meters_per_pixel = float(meters_per_pixel) if meters_per_pixel is not None else None\n",
    "    except:\n",
    "        meters_per_pixel = None\n",
    "    try:\n",
    "        fps_val = float(fps_input) if fps_input is not None else None\n",
    "    except:\n",
    "        fps_val = None\n",
    "\n",
    "    results = {}\n",
    "    if video_file is not None:\n",
    "        # save uploaded file to temp\n",
    "        tmpv = \"input_video.mp4\"\n",
    "        with open(tmpv, \"wb\") as f:\n",
    "            f.write(video_file.read())\n",
    "        out_path, reports, meta = process_video(tmpv, detector, meters_per_pixel=meters_per_pixel, fps=fps_val or meta.get(\"fps\",25.0), speed_threshold_kmph=speed_limit_kmph or None, save_out=\"annotated_out.mp4\")\n",
    "        # return annotated video path and reports\n",
    "        return None, out_path, json.dumps(reports, indent=2)\n",
    "    elif image_file is not None:\n",
    "        # single image detection\n",
    "        if hasattr(image_file, \"name\"):\n",
    "            img = cv2.imread(image_file.name)\n",
    "        else:\n",
    "            b = image_file.read()\n",
    "            arr = np.frombuffer(b, np.uint8)\n",
    "            img = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "        dets = detector.detect_frame(img)\n",
    "        violations, associations = analyze_detections(dets)\n",
    "        ann = draw_boxes(img, dets)\n",
    "        # mark violations text\n",
    "        y0 = 30\n",
    "        repr_reports = []\n",
    "        for v in violations:\n",
    "            if v['type']=='triple_riding':\n",
    "                cv2.putText(ann, f\"Triple Riding (count={v['count']})\", (10,y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2); y0+=25\n",
    "                repr_reports.append({\"type\":\"triple_riding\", \"count\":v['count']})\n",
    "            elif v['type']=='no_helmet':\n",
    "                cv2.putText(ann, \"No Helmet!\", (10,y0), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2); y0+=25\n",
    "                repr_reports.append({\"type\":\"no_helmet\"})\n",
    "        # convert ann to PIL for gr.Image\n",
    "        ann_rgb = cv2.cvtColor(ann, cv2.COLOR_BGR2RGB)\n",
    "        pil_ann = Image.fromarray(ann_rgb)\n",
    "        return pil_ann, None, json.dumps(repr_reports, indent=2)\n",
    "    else:\n",
    "        return None, None, \"Please upload an image or a video.\"\n",
    "\n",
    "# Build Gradio UI\n",
    "with gr.Blocks(title=\"AI Traffic Violation Detector (Helmet / Triple / Speed)\") as demo:\n",
    "    gr.Markdown(\"## ðŸš¨ AI Traffic Violation Detector â€” Helmet, Triple Riding & Approx Speed\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            image_in = gr.File(label=\"Upload Image (jpg/png)\", file_types=[\".png\",\".jpg\",\".jpeg\"])\n",
    "            video_in = gr.File(label=\"Or Upload Video (mp4)\", file_types=[\".mp4\",\".avi\"], interactive=True)\n",
    "            yolo_model_in = gr.File(label=\"YOLO model (optional .pt) e.g., yolov8n.pt\", file_count=\"single\")\n",
    "            helmet_model_in = gr.File(label=\"Helmet model (optional .pt)\", file_count=\"single\")\n",
    "            meters_per_pixel = gr.Number(label=\"Meters per pixel (for speed estimation, e.g., 0.02)\", value=None)\n",
    "            fps_val = gr.Number(label=\"FPS of video (if known)\", value=25)\n",
    "            speed_limit = gr.Number(label=\"Speed limit (km/h) to flag speeding (optional)\", value=60)\n",
    "            run_btn = gr.Button(\"Run Detection\")\n",
    "        with gr.Column(scale=1):\n",
    "            out_image = gr.Image(label=\"Annotated Image (if image uploaded)\", type=\"pil\")\n",
    "            out_video = gr.Video(label=\"Annotated Video (if video uploaded)\")\n",
    "            report_box = gr.Textbox(label=\"Violation Report (JSON)\", lines=12)\n",
    "\n",
    "    run_btn.click(fn=run_on_input, inputs=[image_in, video_in, yolo_model_in, helmet_model_in, meters_per_pixel, fps_val, speed_limit],\n",
    "                  outputs=[out_image, out_video, report_box])\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353a290-fdf8-45f7-81d3-bd277755581a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
