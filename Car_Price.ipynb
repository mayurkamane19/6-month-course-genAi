{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a260968-d3aa-45d7-a11e-2c545bcc6981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\mayur\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 15.8MB/s 0.3s.3s<0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE-CELL YOLO PROJECT READY ✔████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "# ==================== ONE-CELL YOLO11 VEHICLE + LICENSE PLATE PROJECT ====================\n",
    "\n",
    "# ---------------------------------------------\n",
    "# INSTALL PACKAGES\n",
    "# ---------------------------------------------\n",
    "!pip install ultralytics opencv-python easyocr matplotlib --quiet\n",
    "\n",
    "# ---------------------------------------------\n",
    "# IMPORT LIBRARIES\n",
    "# ---------------------------------------------\n",
    "from ultralytics import YOLO\n",
    "import cv2, os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------\n",
    "# TRAINING SETUP (YOU CAN SKIP IF ALREADY TRAINED)\n",
    "# ---------------------------------------------\n",
    "# DATASET STRUCTURE REQUIREMENT (YOLO FORMAT)\n",
    "# data.yaml MUST EXIST IN THIS FORMAT:\n",
    "# train: datasets/images/train\n",
    "# val: datasets/images/val\n",
    "# nc: 2\n",
    "# names: [\"vehicle\", \"license_plate\"]\n",
    "\n",
    "TRAIN_MODEL = False  # TRUE = Train New Model, FALSE = Use Pretrained\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    model = YOLO(\"yolo11n.pt\")  # base model\n",
    "    model.train(\n",
    "        data=\"data.yaml\",  \n",
    "        epochs=10,         # increase for real training\n",
    "        imgsz=640,\n",
    "        batch=8,\n",
    "        name=\"vehicle_lp_model\"\n",
    "    )\n",
    "    model_path = \"runs/detect/vehicle_lp_model/weights/best.pt\"\n",
    "else:\n",
    "    # pretrained or your trained model path\n",
    "    model_path = \"yolo11n.pt\"   # change to best.pt\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# LICENSE PLATE CROPPER\n",
    "# ---------------------------------------------\n",
    "def crop_license_plates(frame, results, lp_class_id=1):\n",
    "    crops = []\n",
    "    for box in results[0].boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        if cls == lp_class_id:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            crops.append(frame[y1:y2, x1:x2])\n",
    "    return crops\n",
    "\n",
    "# ---------------------------------------------\n",
    "# OCR READER\n",
    "# ---------------------------------------------\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "def read_plate(crop):\n",
    "    if crop.size == 0:\n",
    "        return \"\"\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    res = reader.readtext(gray)\n",
    "    if len(res) > 0:\n",
    "        return res[0][1]\n",
    "    return \"\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# IMAGE DETECTION PIPELINE\n",
    "# ---------------------------------------------\n",
    "def detect_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    results = model(img)\n",
    "\n",
    "    # show detection\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(results[0].plot())\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"YOLO11 Vehicle + License Plate Detection\")\n",
    "    plt.show()\n",
    "\n",
    "    # crop + ocr\n",
    "    lp_crops = crop_license_plates(img, results)\n",
    "    for i, crop in enumerate(lp_crops):\n",
    "        text = read_plate(crop)\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Plate {i+1}: {text}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    print(\"OCR RESULT:\", [read_plate(c) for c in lp_crops])\n",
    "\n",
    "# ---------------------------------------------\n",
    "# VIDEO DETECTION PIPELINE\n",
    "# ---------------------------------------------\n",
    "def detect_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model(frame)\n",
    "        annotated = results[0].plot()\n",
    "        \n",
    "        cv2.imshow(\"YOLO11 Vehicle + Plate - VIDEO\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# WEBCAM DETECTION PIPELINE\n",
    "# ---------------------------------------------\n",
    "def detect_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model(frame)\n",
    "        annotated = results[0].plot()\n",
    "\n",
    "        cv2.imshow(\"YOLO11 Vehicle + Plate - WEBCAM\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# RUN EXAMPLES\n",
    "# ---------------------------------------------\n",
    "\n",
    "# 1️⃣ IMAGE DETECTION\n",
    "# detect_image(\"car.jpg\")\n",
    "\n",
    "# 2️⃣ VIDEO DETECTION\n",
    "# detect_video(\"traffic.mp4\")\n",
    "\n",
    "# 3️⃣ WEBCAM LIVE DETECTION\n",
    "# detect_webcam()\n",
    "\n",
    "print(\"ONE-CELL YOLO PROJECT READY ✔\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23be1af4-94ed-44ff-97d2-d6686c9fd14c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'car.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdetect_image\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcar.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mdetect_image\u001b[39m\u001b[34m(img_path)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_image\u001b[39m(img_path):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     img = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     results = model(img)\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# show detection\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:34\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(filename, flags)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m = cv2.IMREAD_COLOR) -> np.ndarray | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read an image from a file with multilanguage filename support.\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m        >>> img = imread(\"path/to/image.jpg\", cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     file_bytes = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filename.endswith((\u001b[33m\"\u001b[39m\u001b[33m.tiff\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.tif\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m     36\u001b[39m         success, frames = cv2.imdecodemulti(file_bytes, cv2.IMREAD_UNCHANGED)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'car.jpg'"
     ]
    }
   ],
   "source": [
    "detect_image(\"car.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da159dee-5b1e-492e-bb90-5f1881c018c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
