{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4fe7b62-04aa-48c7-8e05-9bc7af4ff8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "gr.close_all()\n",
    "\n",
    "# Your image path\n",
    "nano_img = \"/mnt/data/ChatGPT Image Nov 29, 2025, 05_00_07 PM.png\"\n",
    "\n",
    "# ----- SAVE EDITED IMAGE -----\n",
    "def save_edits(edited_img):\n",
    "    return edited_img\n",
    "\n",
    "\n",
    "# ----- ZOOM VIEWER HTML -----\n",
    "def zoom_html():\n",
    "    return f\"\"\"\n",
    "    <style>\n",
    "    #zoom_box {{\n",
    "        width: 100%;\n",
    "        height: 600px;\n",
    "        border: 2px solid #333;\n",
    "        border-radius: 10px;\n",
    "    }}\n",
    "    </style>\n",
    "\n",
    "    <div id=\"zoom_box\"></div>\n",
    "\n",
    "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/openseadragon/4.1.0/openseadragon.min.js\"></script>\n",
    "\n",
    "    <script>\n",
    "    var viewer = OpenSeadragon({{\n",
    "        id: \"zoom_box\",\n",
    "        prefixUrl: \"https://cdnjs.cloudflare.com/ajax/libs/openseadragon/4.1.0/images/\",\n",
    "        tileSources: {{\n",
    "            type: 'image',\n",
    "            url: 'file://{nano_img}'\n",
    "        }},\n",
    "        showNavigator: true,\n",
    "        navigatorPosition: \"BOTTOM_RIGHT\",\n",
    "    }});\n",
    "    </script>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# ---------- UI ----------\n",
    "\n",
    "with gr.Blocks(title=\"Nano-chip Annotator + Zoom Viewer\") as demo:\n",
    "\n",
    "    gr.Markdown(\"## üî¨ **Nano-Chip Annotator + High-Resolution Zoom Viewer**\")\n",
    "\n",
    "    with gr.Tab(\"‚úèÔ∏è Annotate / Draw\"):\n",
    "        gr.Markdown(\"Use drawing tools to mark chip areas, circuits, labels, etc.\")\n",
    "\n",
    "        editor = gr.ImageEditor(\n",
    "            value=nano_img,\n",
    "            label=\"Draw / Box / Text on the nano-chip image\",\n",
    "            height=500\n",
    "        )\n",
    "\n",
    "        save_btn = gr.Button(\"üíæ Save Edited Image\")\n",
    "        saved_output = gr.Image(label=\"Final Annotated Image\")\n",
    "\n",
    "        save_btn.click(save_edits, inputs=editor, outputs=saved_output)\n",
    "\n",
    "\n",
    "    with gr.Tab(\"üîç High-Res Zoom Viewer\"):\n",
    "        gr.Markdown(\"Ultra zoom into microchip details:\")\n",
    "        gr.HTML(zoom_html())\n",
    "\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d32ff2-eb56-42d1-bacf-1bc42282e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nano-chip Annotator + Auto-label + Compare (Upload Required, No Default Image)\n",
    "import os, io, json, cv2, numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import gradio as gr\n",
    "import subprocess, sys\n",
    "\n",
    "gr.close_all()\n",
    "\n",
    "# ----- try to ensure cv2 is installed -----\n",
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\"])\n",
    "    import cv2\n",
    "\n",
    "\n",
    "# ----- Draw bounding boxes -----\n",
    "def draw_boxes_on_pil(pil_img, boxes, labels):\n",
    "    img = pil_img.convert(\"RGBA\")\n",
    "    overlay = Image.new(\"RGBA\", img.size, (0,0,0,0))\n",
    "    draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 18)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for (x,y,w,h), lab in zip(boxes, labels):\n",
    "        x1, y1, x2, y2 = x, y, x+w, y+h\n",
    "        draw.rectangle([x1,y1,x2,y2], outline=(255,165,0), width=3)\n",
    "        tw, th = draw.textsize(lab, font)\n",
    "        draw.rectangle([x1, y1-th-4, x1+tw+6, y1], fill=(0,0,0,150))\n",
    "        draw.text((x1+3,y1-th-2), lab, font=font, fill=(255,255,255))\n",
    "\n",
    "    final = Image.alpha_composite(img, overlay).convert(\"RGB\")\n",
    "    return final\n",
    "\n",
    "\n",
    "# ----- Heuristic detector for chip traces -----\n",
    "def heuristic_detect_components(cv_img):\n",
    "    gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    th = cv2.adaptiveThreshold(\n",
    "        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    h, w = gray.shape\n",
    "    boxes, labels = [], []\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < (h*w)*0.00005:\n",
    "            continue\n",
    "\n",
    "        x,y,wc,hc = cv2.boundingRect(cnt)\n",
    "        ar = wc/float(hc)\n",
    "\n",
    "        if area < (h*w)*0.0008 and 0.8 <= ar <= 1.2:\n",
    "            lab = \"pad\"\n",
    "        elif ar > 4 or ar < 0.25:\n",
    "            lab = \"trace\"\n",
    "        elif area > (h*w)*0.01:\n",
    "            lab = \"component\"\n",
    "        else:\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "            if perimeter > 0:\n",
    "                circularity = 4*np.pi*(area/(perimeter*perimeter))\n",
    "            else:\n",
    "                circularity = 0\n",
    "\n",
    "            lab = \"via\" if circularity > 0.4 else \"component\"\n",
    "\n",
    "        boxes.append((x,y,wc,hc))\n",
    "        labels.append(lab)\n",
    "\n",
    "    return boxes, labels\n",
    "\n",
    "\n",
    "# ----- Main Auto-label + Compare -----\n",
    "def run_auto_label(upload_img, edited_img):\n",
    "    if upload_img is None:\n",
    "        return None, None, None, \"Please upload an image first!\"\n",
    "\n",
    "    # Convert upload to cv format\n",
    "    pil = Image.open(upload_img.name).convert(\"RGB\")\n",
    "    cv_img = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Run heuristic labeling\n",
    "    boxes, labels = heuristic_detect_components(cv_img)\n",
    "    auto_pil = draw_boxes_on_pil(pil, boxes, labels)\n",
    "\n",
    "    # Prepare edited image\n",
    "    if isinstance(edited_img, np.ndarray):\n",
    "        edited_pil = Image.fromarray(edited_img.astype(\"uint8\"))\n",
    "    else:\n",
    "        edited_pil = pil.copy()\n",
    "\n",
    "    # Side-by-side comparison image\n",
    "    h = max(pil.height, auto_pil.height, edited_pil.height)\n",
    "    def resize(img): return img.resize((int(img.width*(h/img.height)), h))\n",
    "\n",
    "    o = resize(pil)\n",
    "    a = resize(auto_pil)\n",
    "    e = resize(edited_pil)\n",
    "\n",
    "    final = Image.new(\"RGB\", (o.width + a.width + e.width + 40, h), (30,30,30))\n",
    "    final.paste(o, (10,0))\n",
    "    final.paste(a, (o.width+20,0))\n",
    "    final.paste(e, (o.width+a.width+30,0))\n",
    "\n",
    "    # JSON annotations\n",
    "    ann = {\"annotations\":[]}\n",
    "    for (x,y,wc,hc), lab in zip(boxes, labels):\n",
    "        ann[\"annotations\"].append({\n",
    "            \"label\": lab, \"x\":x, \"y\":y, \"w\":wc, \"h\":hc\n",
    "        })\n",
    "\n",
    "    return auto_pil, final, json.dumps(ann, indent=2), None\n",
    "\n",
    "\n",
    "# ----- Build UI -----\n",
    "with gr.Blocks(title=\"Nano-chip Auto-Label Annotator\") as demo:\n",
    "\n",
    "    gr.Markdown(\"## üî¨ Nano-Chip Auto-Label + Editor + Side-by-Side Compare\")\n",
    "\n",
    "    upload = gr.File(label=\"Upload Nano-chip Image (.png/.jpg)\")\n",
    "    editor = gr.ImageEditor(label=\"Draw / Edit before auto-label\", height=450)\n",
    "\n",
    "    run_btn = gr.Button(\"ü™Ñ Auto-Label & Compare\", variant=\"primary\")\n",
    "\n",
    "    auto_out = gr.Image(label=\"Auto-Labeled Image\")\n",
    "    sbs_out = gr.Image(label=\"Side-by-side (Original | Auto | Edited)\")\n",
    "    json_out = gr.Textbox(label=\"Annotations JSON\", lines=12)\n",
    "\n",
    "    msg_out = gr.Textbox(label=\"Messages\")\n",
    "\n",
    "    run_btn.click(\n",
    "        fn=run_auto_label,\n",
    "        inputs=[upload, editor],\n",
    "        outputs=[auto_out, sbs_out, json_out, msg_out]\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69356f-8b7c-495b-a8e4-f073741d8a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
